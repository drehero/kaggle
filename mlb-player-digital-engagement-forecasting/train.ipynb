{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Tp5-5XbwZtU1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1627162624811,
     "user": {
      "displayName": "Robin Dreher",
      "photoUrl": "",
      "userId": "09202012261918195247"
     },
     "user_tz": -120
    },
    "id": "Tp5-5XbwZtU1",
    "outputId": "5192a44a-e5d1-4dfd-e00d-d71933d238b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fwe-GnlmchWA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "executionInfo": {
     "elapsed": 14216,
     "status": "ok",
     "timestamp": 1627162573773,
     "user": {
      "displayName": "Robin Dreher",
      "photoUrl": "",
      "userId": "09202012261918195247"
     },
     "user_tz": -120
    },
    "id": "fwe-GnlmchWA",
    "outputId": "b4d8b782-fa56-4853-b9e8-8b73cbe19521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.2.4\n",
      "  Downloading pandas-1.2.4-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 5.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.2.4) (1.15.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.5\n",
      "    Uninstalling pandas-1.1.5:\n",
      "      Successfully uninstalled pandas-1.1.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.2.4 which is incompatible.\u001b[0m\n",
      "Successfully installed pandas-1.2.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pandas"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install pandas==1.2.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R_u_hdI5blTV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1036,
     "status": "ok",
     "timestamp": 1627162629988,
     "user": {
      "displayName": "Robin Dreher",
      "photoUrl": "",
      "userId": "09202012261918195247"
     },
     "user_tz": -120
    },
    "id": "R_u_hdI5blTV",
    "outputId": "52c35f2d-1034-42aa-8fc8-1f0af4ef0970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.12.0\n",
      "alabaster==0.7.12\n",
      "albumentations==0.1.12\n",
      "altair==4.1.0\n",
      "appdirs==1.4.4\n",
      "argon2-cffi==20.1.0\n",
      "arviz==0.11.2\n",
      "astor==0.8.1\n",
      "astropy==4.2.1\n",
      "astunparse==1.6.3\n",
      "async-generator==1.10\n",
      "atari-py==0.2.9\n",
      "atomicwrites==1.4.0\n",
      "attrs==21.2.0\n",
      "audioread==2.1.9\n",
      "autograd==1.3\n",
      "Babel==2.9.1\n",
      "backcall==0.2.0\n",
      "beautifulsoup4==4.6.3\n",
      "bleach==3.3.0\n",
      "blis==0.4.1\n",
      "bokeh==2.3.3\n",
      "Bottleneck==1.3.2\n",
      "branca==0.4.2\n",
      "bs4==0.0.1\n",
      "CacheControl==0.12.6\n",
      "cached-property==1.5.2\n",
      "cachetools==4.2.2\n",
      "catalogue==1.0.0\n",
      "certifi==2021.5.30\n",
      "cffi==1.14.6\n",
      "cftime==1.5.0\n",
      "chardet==3.0.4\n",
      "charset-normalizer==2.0.2\n",
      "click==7.1.2\n",
      "cloudpickle==1.3.0\n",
      "cmake==3.12.0\n",
      "cmdstanpy==0.9.5\n",
      "colorcet==2.0.6\n",
      "colorlover==0.3.0\n",
      "community==1.0.0b1\n",
      "contextlib2==0.5.5\n",
      "convertdate==2.3.2\n",
      "coverage==3.7.1\n",
      "coveralls==0.5\n",
      "crcmod==1.7\n",
      "cufflinks==0.17.3\n",
      "cvxopt==1.2.6\n",
      "cvxpy==1.0.31\n",
      "cycler==0.10.0\n",
      "cymem==2.0.5\n",
      "Cython==0.29.23\n",
      "daft==0.0.4\n",
      "dask==2.12.0\n",
      "datascience==0.10.6\n",
      "debugpy==1.0.0\n",
      "decorator==4.4.2\n",
      "defusedxml==0.7.1\n",
      "descartes==1.1.0\n",
      "dill==0.3.4\n",
      "distributed==1.25.3\n",
      "dlib @ file:///dlib-19.18.0-cp37-cp37m-linux_x86_64.whl\n",
      "dm-tree==0.1.6\n",
      "docopt==0.6.2\n",
      "docutils==0.17.1\n",
      "dopamine-rl==1.0.5\n",
      "earthengine-api==0.1.272\n",
      "easydict==1.9\n",
      "ecos==2.0.7.post1\n",
      "editdistance==0.5.3\n",
      "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\n",
      "entrypoints==0.3\n",
      "ephem==4.0.0.2\n",
      "et-xmlfile==1.1.0\n",
      "fa2==0.3.5\n",
      "fastai==1.0.61\n",
      "fastdtw==0.3.4\n",
      "fastprogress==1.0.0\n",
      "fastrlock==0.6\n",
      "fbprophet==0.7.1\n",
      "feather-format==0.4.1\n",
      "filelock==3.0.12\n",
      "firebase-admin==4.4.0\n",
      "fix-yahoo-finance==0.0.22\n",
      "Flask==1.1.4\n",
      "flatbuffers==1.12\n",
      "folium==0.8.3\n",
      "future==0.16.0\n",
      "gast==0.4.0\n",
      "GDAL==2.2.2\n",
      "gdown==3.6.4\n",
      "gensim==3.6.0\n",
      "geographiclib==1.52\n",
      "geopy==1.17.0\n",
      "gin-config==0.4.0\n",
      "glob2==0.7\n",
      "google==2.0.3\n",
      "google-api-core==1.26.3\n",
      "google-api-python-client==1.12.8\n",
      "google-auth==1.32.1\n",
      "google-auth-httplib2==0.0.4\n",
      "google-auth-oauthlib==0.4.4\n",
      "google-cloud-bigquery==1.21.0\n",
      "google-cloud-bigquery-storage==1.1.0\n",
      "google-cloud-core==1.0.3\n",
      "google-cloud-datastore==1.8.0\n",
      "google-cloud-firestore==1.7.0\n",
      "google-cloud-language==1.2.0\n",
      "google-cloud-storage==1.18.1\n",
      "google-cloud-translate==1.5.0\n",
      "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\n",
      "google-pasta==0.2.0\n",
      "google-resumable-media==0.4.1\n",
      "googleapis-common-protos==1.53.0\n",
      "googledrivedownloader==0.4\n",
      "graphviz==0.10.1\n",
      "greenlet==1.1.0\n",
      "grpcio==1.34.1\n",
      "gspread==3.0.1\n",
      "gspread-dataframe==3.0.8\n",
      "gym==0.17.3\n",
      "h5py==3.1.0\n",
      "HeapDict==1.0.1\n",
      "hijri-converter==2.1.3\n",
      "holidays==0.10.5.2\n",
      "holoviews==1.14.4\n",
      "html5lib==1.0.1\n",
      "httpimport==0.5.18\n",
      "httplib2==0.17.4\n",
      "httplib2shim==0.0.3\n",
      "humanize==0.5.1\n",
      "hyperopt==0.1.2\n",
      "ideep4py==2.0.0.post3\n",
      "idna==2.10\n",
      "imageio==2.4.1\n",
      "imagesize==1.2.0\n",
      "imbalanced-learn==0.4.3\n",
      "imblearn==0.0\n",
      "imgaug==0.2.9\n",
      "importlib-metadata==4.6.1\n",
      "importlib-resources==5.2.0\n",
      "imutils==0.5.4\n",
      "inflect==2.1.0\n",
      "iniconfig==1.1.1\n",
      "install==1.3.4\n",
      "intel-openmp==2021.3.0\n",
      "intervaltree==2.1.0\n",
      "ipykernel==4.10.1\n",
      "ipython==5.5.0\n",
      "ipython-genutils==0.2.0\n",
      "ipython-sql==0.3.9\n",
      "ipywidgets==7.6.3\n",
      "itsdangerous==1.1.0\n",
      "jax==0.2.17\n",
      "jaxlib @ https://storage.googleapis.com/jax-releases/cuda110/jaxlib-0.1.69+cuda110-cp37-none-manylinux2010_x86_64.whl\n",
      "jdcal==1.4.1\n",
      "jedi==0.18.0\n",
      "jieba==0.42.1\n",
      "Jinja2==2.11.3\n",
      "joblib==1.0.1\n",
      "jpeg4py==0.1.4\n",
      "jsonschema==2.6.0\n",
      "jupyter==1.0.0\n",
      "jupyter-client==5.3.5\n",
      "jupyter-console==5.2.0\n",
      "jupyter-core==4.7.1\n",
      "jupyterlab-pygments==0.1.2\n",
      "jupyterlab-widgets==1.0.0\n",
      "kaggle==1.5.12\n",
      "kapre==0.3.5\n",
      "Keras==2.4.3\n",
      "keras-nightly==2.5.0.dev2021032900\n",
      "Keras-Preprocessing==1.1.2\n",
      "keras-vis==0.4.1\n",
      "kiwisolver==1.3.1\n",
      "korean-lunar-calendar==0.2.1\n",
      "librosa==0.8.1\n",
      "lightgbm==2.2.3\n",
      "llvmlite==0.34.0\n",
      "lmdb==0.99\n",
      "LunarCalendar==0.0.9\n",
      "lxml==4.2.6\n",
      "Markdown==3.3.4\n",
      "MarkupSafe==2.0.1\n",
      "matplotlib==3.2.2\n",
      "matplotlib-inline==0.1.2\n",
      "matplotlib-venn==0.11.6\n",
      "missingno==0.5.0\n",
      "mistune==0.8.4\n",
      "mizani==0.6.0\n",
      "mkl==2019.0\n",
      "mlxtend==0.14.0\n",
      "more-itertools==8.8.0\n",
      "moviepy==0.2.3.5\n",
      "mpmath==1.2.1\n",
      "msgpack==1.0.2\n",
      "multiprocess==0.70.12.2\n",
      "multitasking==0.0.9\n",
      "murmurhash==1.0.5\n",
      "music21==5.5.0\n",
      "natsort==5.5.0\n",
      "nbclient==0.5.3\n",
      "nbconvert==5.6.1\n",
      "nbformat==5.1.3\n",
      "nest-asyncio==1.5.1\n",
      "netCDF4==1.5.7\n",
      "networkx==2.5.1\n",
      "nibabel==3.0.2\n",
      "nltk==3.2.5\n",
      "notebook==5.3.1\n",
      "numba==0.51.2\n",
      "numexpr==2.7.3\n",
      "numpy==1.19.5\n",
      "nvidia-ml-py3==7.352.0\n",
      "oauth2client==4.1.3\n",
      "oauthlib==3.1.1\n",
      "okgrade==0.4.3\n",
      "opencv-contrib-python==4.1.2.30\n",
      "opencv-python==4.1.2.30\n",
      "openpyxl==2.5.9\n",
      "opt-einsum==3.3.0\n",
      "osqp==0.6.2.post0\n",
      "packaging==21.0\n",
      "palettable==3.3.0\n",
      "pandas==1.2.4\n",
      "pandas-datareader==0.9.0\n",
      "pandas-gbq==0.13.3\n",
      "pandas-profiling==1.4.1\n",
      "pandocfilters==1.4.3\n",
      "panel==0.11.3\n",
      "param==1.11.1\n",
      "parso==0.8.2\n",
      "pathlib==1.0.1\n",
      "patsy==0.5.1\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "Pillow==7.1.2\n",
      "pip-tools==4.5.1\n",
      "plac==1.1.3\n",
      "plotly==4.4.1\n",
      "plotnine==0.6.0\n",
      "pluggy==0.7.1\n",
      "pooch==1.4.0\n",
      "portpicker==1.3.9\n",
      "prefetch-generator==1.0.1\n",
      "preshed==3.0.5\n",
      "prettytable==2.1.0\n",
      "progressbar2==3.38.0\n",
      "prometheus-client==0.11.0\n",
      "promise==2.3\n",
      "prompt-toolkit==1.0.18\n",
      "protobuf==3.17.3\n",
      "psutil==5.4.8\n",
      "psycopg2==2.7.6.1\n",
      "ptyprocess==0.7.0\n",
      "py==1.10.0\n",
      "pyarrow==3.0.0\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycocotools==2.0.2\n",
      "pycparser==2.20\n",
      "pyct==0.4.8\n",
      "pydata-google-auth==1.2.0\n",
      "pydot==1.3.0\n",
      "pydot-ng==2.0.0\n",
      "pydotplus==2.0.2\n",
      "PyDrive==1.3.1\n",
      "pyemd==0.5.1\n",
      "pyerfa==2.0.0\n",
      "pyglet==1.5.0\n",
      "Pygments==2.6.1\n",
      "pygobject==3.26.1\n",
      "pymc3==3.11.2\n",
      "PyMeeus==0.5.11\n",
      "pymongo==3.11.4\n",
      "pymystem3==0.2.0\n",
      "PyOpenGL==3.1.5\n",
      "pyparsing==2.4.7\n",
      "pyrsistent==0.18.0\n",
      "pysndfile==1.3.8\n",
      "PySocks==1.7.1\n",
      "pystan==2.19.1.1\n",
      "pytest==3.6.4\n",
      "python-apt==0.0.0\n",
      "python-chess==0.23.11\n",
      "python-dateutil==2.8.1\n",
      "python-louvain==0.15\n",
      "python-slugify==5.0.2\n",
      "python-utils==2.5.6\n",
      "pytz==2018.9\n",
      "pyviz-comms==2.1.0\n",
      "PyWavelets==1.1.1\n",
      "PyYAML==3.13\n",
      "pyzmq==22.1.0\n",
      "qdldl==0.1.5.post0\n",
      "qtconsole==5.1.1\n",
      "QtPy==1.9.0\n",
      "regex==2019.12.20\n",
      "requests==2.23.0\n",
      "requests-oauthlib==1.3.0\n",
      "resampy==0.2.2\n",
      "retrying==1.3.3\n",
      "rpy2==3.4.5\n",
      "rsa==4.7.2\n",
      "scikit-image==0.16.2\n",
      "scikit-learn==0.22.2.post1\n",
      "scipy==1.4.1\n",
      "screen-resolution-extra==0.0.0\n",
      "scs==2.1.4\n",
      "seaborn==0.11.1\n",
      "semver==2.13.0\n",
      "Send2Trash==1.7.1\n",
      "setuptools-git==1.2\n",
      "Shapely==1.7.1\n",
      "simplegeneric==0.8.1\n",
      "six==1.15.0\n",
      "sklearn==0.0\n",
      "sklearn-pandas==1.8.0\n",
      "smart-open==5.1.0\n",
      "snowballstemmer==2.1.0\n",
      "sortedcontainers==2.4.0\n",
      "SoundFile==0.10.3.post1\n",
      "spacy==2.2.4\n",
      "Sphinx==1.8.5\n",
      "sphinxcontrib-serializinghtml==1.1.5\n",
      "sphinxcontrib-websupport==1.2.4\n",
      "SQLAlchemy==1.4.20\n",
      "sqlparse==0.4.1\n",
      "srsly==1.0.5\n",
      "statsmodels==0.10.2\n",
      "sympy==1.7.1\n",
      "tables==3.4.4\n",
      "tabulate==0.8.9\n",
      "tblib==1.7.0\n",
      "tensorboard==2.5.0\n",
      "tensorboard-data-server==0.6.1\n",
      "tensorboard-plugin-wit==1.8.0\n",
      "tensorflow @ file:///tensorflow-2.5.0-cp37-cp37m-linux_x86_64.whl\n",
      "tensorflow-datasets==4.0.1\n",
      "tensorflow-estimator==2.5.0\n",
      "tensorflow-gcs-config==2.5.0\n",
      "tensorflow-hub==0.12.0\n",
      "tensorflow-metadata==1.1.0\n",
      "tensorflow-probability==0.13.0\n",
      "termcolor==1.1.0\n",
      "terminado==0.10.1\n",
      "testpath==0.5.0\n",
      "text-unidecode==1.3\n",
      "textblob==0.15.3\n",
      "Theano-PyMC==1.1.2\n",
      "thinc==7.4.0\n",
      "tifffile==2021.7.2\n",
      "toml==0.10.2\n",
      "toolz==0.11.1\n",
      "torch @ https://download.pytorch.org/whl/cu102/torch-1.9.0%2Bcu102-cp37-cp37m-linux_x86_64.whl\n",
      "torchsummary==1.5.1\n",
      "torchtext==0.10.0\n",
      "torchvision @ https://download.pytorch.org/whl/cu102/torchvision-0.10.0%2Bcu102-cp37-cp37m-linux_x86_64.whl\n",
      "tornado==5.1.1\n",
      "tqdm==4.41.1\n",
      "traitlets==5.0.5\n",
      "tweepy==3.10.0\n",
      "typeguard==2.7.1\n",
      "typing-extensions==3.7.4.3\n",
      "tzlocal==1.5.1\n",
      "uritemplate==3.0.1\n",
      "urllib3==1.24.3\n",
      "vega-datasets==0.9.0\n",
      "wasabi==0.8.2\n",
      "wcwidth==0.2.5\n",
      "webencodings==0.5.1\n",
      "Werkzeug==1.0.1\n",
      "widgetsnbextension==3.5.1\n",
      "wordcloud==1.5.0\n",
      "wrapt==1.12.1\n",
      "xarray==0.18.2\n",
      "xgboost==0.90\n",
      "xkit==0.0.0\n",
      "xlrd==1.1.0\n",
      "xlwt==1.3.0\n",
      "yellowbrick==0.9.1\n",
      "zict==2.0.0\n",
      "zipp==3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l4dHnHKYmstR",
   "metadata": {
    "id": "l4dHnHKYmstR"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/mlb/config.py .\n",
    "!cp /content/drive/MyDrive/mlb/preprocessing.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc252d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:48:14.733262Z",
     "iopub.status.busy": "2021-07-21T04:48:14.732566Z",
     "iopub.status.idle": "2021-07-21T04:48:20.644746Z",
     "shell.execute_reply": "2021-07-21T04:48:20.645271Z",
     "shell.execute_reply.started": "2021-07-21T04:16:56.060824Z"
    },
    "id": "3cc252d1",
    "papermill": {
     "duration": 5.928961,
     "end_time": "2021-07-21T04:48:20.645448",
     "exception": false,
     "start_time": "2021-07-21T04:48:14.716487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "from config import *\n",
    "\n",
    "import gc\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab0625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:48:20.674417Z",
     "iopub.status.busy": "2021-07-21T04:48:20.673423Z",
     "iopub.status.idle": "2021-07-21T04:48:20.678877Z",
     "shell.execute_reply": "2021-07-21T04:48:20.678311Z",
     "shell.execute_reply.started": "2021-07-21T04:17:01.095180Z"
    },
    "id": "6dab0625",
    "papermill": {
     "duration": 0.021186,
     "end_time": "2021-07-21T04:48:20.679027",
     "exception": false,
     "start_time": "2021-07-21T04:48:20.657841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH_TO_MLB_DATA = BASE_DIR / \"data/mlb-player-digital-engagement-forecasting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da4f60e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:48:20.709620Z",
     "iopub.status.busy": "2021-07-21T04:48:20.708922Z",
     "iopub.status.idle": "2021-07-21T04:49:29.549032Z",
     "shell.execute_reply": "2021-07-21T04:49:29.549666Z",
     "shell.execute_reply.started": "2021-07-21T04:17:01.100647Z"
    },
    "id": "4da4f60e",
    "papermill": {
     "duration": 68.858714,
     "end_time": "2021-07-21T04:49:29.549863",
     "exception": false,
     "start_time": "2021-07-21T04:48:20.691149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH_TO_MLB_DATA / \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe4e98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-07-21T04:49:29.577751Z",
     "iopub.status.busy": "2021-07-21T04:49:29.576973Z",
     "iopub.status.idle": "2021-07-21T04:57:34.658230Z",
     "shell.execute_reply": "2021-07-21T04:57:34.658704Z",
     "shell.execute_reply.started": "2021-07-21T04:18:01.461908Z"
    },
    "id": "eafe4e98",
    "outputId": "adfa5014-2b4b-4331-db3a-386efe81699d",
    "papermill": {
     "duration": 485.096682,
     "end_time": "2021-07-21T04:57:34.658903",
     "exception": false,
     "start_time": "2021-07-21T04:49:29.562221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# lagged targets\n",
      "# players\n",
      "# rosters\n",
      "# teams\n",
      "# games\n",
      "# player box scores\n",
      "# transactions\n",
      "# awards\n",
      "# events\n"
     ]
    }
   ],
   "source": [
    "# prepare training data\n",
    "\n",
    "# dates and next day player enagagement\n",
    "unpacked_next_day_player_engagement = unpack_data(train, [\"nextDayPlayerEngagement\"])[\"nextDayPlayerEngagement\"]\n",
    "del(train[\"nextDayPlayerEngagement\"])\n",
    "gc.collect()\n",
    "seasons = pd.read_csv(PATH_TO_MLB_DATA / \"seasons.csv\")\n",
    "dates_with_info = get_dates_with_info(unpacked_next_day_player_engagement, seasons)\n",
    "del(seasons)\n",
    "gc.collect()\n",
    "train_df = unpacked_next_day_player_engagement.merge(dates_with_info, on=\"dailyDataDate\", how=\"left\")\n",
    "del(dates_with_info)\n",
    "gc.collect()\n",
    "\n",
    "print(\"# lagged targets\")\n",
    "for lag in range(1, N_LAGS+1):\n",
    "    lagged_targets = get_lagged_targets_train(unpacked_next_day_player_engagement, lag)\n",
    "    train_df = train_df.merge(lagged_targets, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "    del(lagged_targets)\n",
    "    gc.collect()\n",
    "del(unpacked_next_day_player_engagement)\n",
    "gc.collect\n",
    "\n",
    "#print(\"# player target stats\")\n",
    "#player_target_stats = get_player_target_stats(unpacked_next_day_player_engagement)\n",
    "#train_df = train_df.merge(player_target_stats, on=\"playerId\", how=\"left\")\n",
    "#del(player_target_stats, unpacked_next_day_player_engagement)\n",
    "#gc.collect\n",
    "\n",
    "print(\"# players\")\n",
    "players = pd.read_csv(PATH_TO_MLB_DATA / \"players.csv\")\n",
    "players_to_merge = prepare_players(players)\n",
    "del(players)\n",
    "gc.collect()\n",
    "train_df = train_df.merge(players_to_merge, on=\"playerId\", how=\"left\")\n",
    "del(players_to_merge)\n",
    "gc.collect()\n",
    "\n",
    "print(\"# rosters\")\n",
    "unpacked_rosters = unpack_data(train, [\"rosters\"])[\"rosters\"]\n",
    "del(train[\"rosters\"])\n",
    "gc.collect()\n",
    "rosters_to_merge = prepare_rosters(unpacked_rosters)\n",
    "del(unpacked_rosters)\n",
    "gc.collect()\n",
    "train_df = train_df.merge(rosters_to_merge, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "del(rosters_to_merge)\n",
    "gc.collect()\n",
    "\n",
    "print(\"# teams\")\n",
    "teams = pd.read_csv(PATH_TO_MLB_DATA / \"teams.csv\")\n",
    "teams_to_merge = prepare_teams(teams)\n",
    "del(teams)\n",
    "gc.collect()\n",
    "train_df = train_df.merge(teams_to_merge, on=\"teamId\", how=\"left\")\n",
    "del(teams_to_merge)\n",
    "gc.collect()\n",
    "\n",
    "print(\"# games\")\n",
    "unpacked_games = unpack_data(train, [\"games\"])[\"games\"]\n",
    "del(train[\"games\"])\n",
    "gc.collect()\n",
    "games_to_merge = prepare_games(unpacked_games)\n",
    "train_df = train_df.merge(games_to_merge, on=[\"dailyDataDate\", \"teamId\"], how=\"left\")\n",
    "del(games_to_merge)\n",
    "gc.collect()\n",
    "\n",
    "# team box scores\n",
    "#unpacked_team_box_scores = unpack_data(train, [\"teamBoxScores\"])[\"teamBoxScores\"]\n",
    "#del(train[\"teamBoxScores\"])\n",
    "#gc.collect()\n",
    "#team_box_scores_to_merge = prepare_team_box_scores(unpacked_team_box_scores)\n",
    "#del(unpacked_team_box_scores)\n",
    "#gc.collect()\n",
    "#train_df = train_df.merge(team_box_scores_to_merge, on=[\"dailyDataDate\", \"teamId\"], how=\"left\")\n",
    "#del(team_box_scores_to_merge)\n",
    "#gc.collect()\n",
    "\n",
    "print(\"# player box scores\")\n",
    "unpacked_player_box_scores = unpack_data(train, [\"playerBoxScores\"])[\"playerBoxScores\"]\n",
    "del(train[\"playerBoxScores\"])\n",
    "gc.collect()\n",
    "player_box_scores_to_merge = prepare_player_box_scores(unpacked_player_box_scores)\n",
    "del(unpacked_player_box_scores)\n",
    "gc.collect()\n",
    "train_df = train_df.merge(player_box_scores_to_merge, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "del(player_box_scores_to_merge)\n",
    "gc.collect()\n",
    "\n",
    "print(\"# transactions\")\n",
    "unpacked_transactions = unpack_data(train, [\"transactions\"])[\"transactions\"]\n",
    "del(train[\"transactions\"])\n",
    "gc.collect()\n",
    "transactions_to_merge = prepare_transactions(unpacked_transactions)\n",
    "del(unpacked_transactions)\n",
    "gc.collect()\n",
    "train_df = train_df.merge(transactions_to_merge, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "del(transactions_to_merge)\n",
    "gc.collect()\n",
    "\n",
    "print(\"# awards\")\n",
    "unpacked_awards = unpack_data(train, [\"awards\"])[\"awards\"]\n",
    "del(train[\"awards\"])\n",
    "gc.collect()\n",
    "awards_to_merge = prepare_awards(unpacked_awards)\n",
    "del(unpacked_awards)\n",
    "gc.collect()\n",
    "train_df = train_df.merge(awards_to_merge, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "del(awards_to_merge)\n",
    "gc.collect()\n",
    "\n",
    "print(\"# events\")\n",
    "unpacked_events = unpack_data(train, [\"events\"])[\"events\"]\n",
    "del(train[\"events\"])\n",
    "gc.collect()\n",
    "events_to_merge = prepare_events(unpacked_events, unpacked_games)\n",
    "del(unpacked_events, unpacked_games)\n",
    "gc.collect()\n",
    "train_df = train_df.merge(events_to_merge, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "del(events_to_merge)\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "print(\"# standings\")\n",
    "unpacked_standings = unpack_data(train, [\"standings\"])[\"standings\"]\n",
    "del(train[\"standings\"])\n",
    "gc.collect()\n",
    "standings_to_merge = prepare_standings(unpacked_standings)\n",
    "del(unpacked_standings)\n",
    "gc.collect()\n",
    "train_df = train_df.merge(standings_to_merge, on=[\"dailyDataDate\", \"teamId\"], how=\"left\")\n",
    "del(standings_to_merge)\n",
    "gc.collect()\n",
    "\n",
    "print(\"# player twitter followers\")\n",
    "unpacked_player_twitter_followers = unpack_data(train, [\"playerTwitterFollowers\"])[\"playerTwitterFollowers\"]\n",
    "del(train[\"playerTwitterFollowers\"])\n",
    "gc.collect()\n",
    "train_df = pd.merge_asof(train_df, unpacked_player_twitter_followers.loc[:, ('date', 'playerId', 'numberOfFollowers')].rename(\n",
    "    columns={\"numberOfFollowers\": \"numberOfFollowersPlayer\"}), on=\"date\", by=\"playerId\", direction=\"backward\")\n",
    "del(unpacked_player_twitter_followers)\n",
    "gc.collect()\n",
    "\n",
    "print(\"# team twitter followers\")\n",
    "unpacked_team_twitter_followers = unpack_data(train, [\"teamTwitterFollowers\"])[\"teamTwitterFollowers\"]\n",
    "del(train)\n",
    "gc.collect()\n",
    "unpacked_team_twitter_followers[\"teamId\"] = unpacked_team_twitter_followers[\"teamId\"].astype(str)\n",
    "train_df = pd.merge_asof(train_df, unpacked_team_twitter_followers.loc[:, (\"date\", \"teamId\", \"numberOfFollowers\")].rename(\n",
    "    columns={\"numberOfFollowers\": \"numberOfFollowersTeam\"}), on=\"date\", by=\"teamId\", direction=\"backward\")\n",
    "del(unpacked_team_twitter_followers)\n",
    "gc.collect()\n",
    "\n",
    "print(\"# mlb social media\")\n",
    "mlb_social_media = pd.read_csv(BASE_DIR / \"data/teams.csv\")\n",
    "mlb_social_media = prepare_mlb_social_media(mlb_social_media)\n",
    "train_df = train_df.merge(mlb_social_media, on=\"teamId\", how=\"left\")\n",
    "del(mlb_social_media)\n",
    "gc.collect()\n",
    "\n",
    "print(\"# player salaries\")\n",
    "players = pd.read_csv(PATH_TO_MLB_DATA / \"players.csv\")\n",
    "player_salaries = pd.read_csv(BASE_DIR / \"data/mlbSalaries.csv\")\n",
    "player_salaries_to_merge = prepare_player_salaries(player_salaries, players)\n",
    "del(player_salaries, players)\n",
    "gc.collect()\n",
    "train_df = train_df.merge(player_salaries_to_merge, on=[\"playerId\", \"year\"], how=\"left\")\n",
    "del(player_salaries_to_merge)\n",
    "gc.collect()\n",
    "\n",
    "train_df.fillna(COLUMN_DEFAULTS, inplace=True)\n",
    "for feature_name in train_df.columns:\n",
    "    if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "        train_df[feature_name] = train_df[feature_name].astype(str)\n",
    "train_df = train_df.loc[:, FEATURE_NAMES + TARGET_FEATURE_NAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd50e98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:57:34.983230Z",
     "iopub.status.busy": "2021-07-21T04:57:34.982563Z",
     "iopub.status.idle": "2021-07-21T04:57:56.019770Z",
     "shell.execute_reply": "2021-07-21T04:57:56.020217Z",
     "shell.execute_reply.started": "2021-07-21T04:25:52.555423Z"
    },
    "id": "ddd50e98",
    "outputId": "0dbc1960-5090-4bd7-f939-12a799ec5aee",
    "papermill": {
     "duration": 21.34587,
     "end_time": "2021-07-21T04:57:56.020382",
     "exception": false,
     "start_time": "2021-07-21T04:57:34.674512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use april as holdout\n",
    "val_df = train_df[((train_df[\"year\"] == \"2021\") & (train_df[\"month\"] == \"4\"))]\n",
    "\n",
    "train_df.drop(val_df.index, inplace=True)\n",
    "train_df = train_df.sample(frac=1)  # shuffle\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e43962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:57:56.057436Z",
     "iopub.status.busy": "2021-07-21T04:57:56.056749Z",
     "iopub.status.idle": "2021-07-21T04:57:57.972147Z",
     "shell.execute_reply": "2021-07-21T04:57:57.971598Z",
     "shell.execute_reply.started": "2021-07-21T04:26:12.613630Z"
    },
    "id": "a3e43962",
    "papermill": {
     "duration": 1.936554,
     "end_time": "2021-07-21T04:57:57.972299",
     "exception": false,
     "start_time": "2021-07-21T04:57:56.035745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# precompute mean and variance for the normalization layer\n",
    "NUMERIC_FEATURES_MEAN = {}\n",
    "NUMERIC_FEATURES_VARIANCE = {}\n",
    "for feature_name in NUMERIC_FEATURE_NAMES:\n",
    "    NUMERIC_FEATURES_MEAN[feature_name] = train_df[feature_name].mean()\n",
    "    NUMERIC_FEATURES_VARIANCE[feature_name] = train_df[feature_name].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c3aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:57:59.079174Z",
     "iopub.status.busy": "2021-07-21T04:57:59.078501Z",
     "iopub.status.idle": "2021-07-21T04:58:24.375772Z",
     "shell.execute_reply": "2021-07-21T04:58:24.375210Z",
     "shell.execute_reply.started": "2021-07-21T04:26:14.460073Z"
    },
    "id": "577c3aa7",
    "papermill": {
     "duration": 26.388087,
     "end_time": "2021-07-21T04:58:24.375921",
     "exception": false,
     "start_time": "2021-07-21T04:57:57.987834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get vocabulary for categorical features\n",
    "n = 100\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {}\n",
    "for feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "    categories_value_count_greater_n = train_df[feature_name].value_counts().index[train_df[feature_name].value_counts() > n]\n",
    "    CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name] = list(categories_value_count_greater_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff886a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:58:24.413604Z",
     "iopub.status.busy": "2021-07-21T04:58:24.412965Z",
     "iopub.status.idle": "2021-07-21T04:58:24.415852Z",
     "shell.execute_reply": "2021-07-21T04:58:24.415231Z",
     "shell.execute_reply.started": "2021-07-21T04:26:40.561359Z"
    },
    "id": "03ff886a",
    "papermill": {
     "duration": 0.024381,
     "end_time": "2021-07-21T04:58:24.415989",
     "exception": false,
     "start_time": "2021-07-21T04:58:24.391608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(1, ), dtype=tf.string\n",
    "            )\n",
    "        else:\n",
    "            # numeric and binary features\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(1, ), dtype=tf.float32\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea073ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:58:24.457919Z",
     "iopub.status.busy": "2021-07-21T04:58:24.457229Z",
     "iopub.status.idle": "2021-07-21T04:58:24.460067Z",
     "shell.execute_reply": "2021-07-21T04:58:24.459536Z",
     "shell.execute_reply.started": "2021-07-21T04:26:40.568151Z"
    },
    "id": "9ea073ab",
    "papermill": {
     "duration": 0.028669,
     "end_time": "2021-07-21T04:58:24.460202",
     "exception": false,
     "start_time": "2021-07-21T04:58:24.431533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature Encoding\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization(mean=NUMERIC_FEATURES_MEAN[name], variance=NUMERIC_FEATURES_VARIANCE[name])\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, use_embedding):\n",
    "    # Create a lookup layer which will turn values into integer indices\n",
    "    vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[name]\n",
    "    vocab_size = len(vocabulary)\n",
    "    lookup = StringLookup(num_oov_indices=1, vocabulary=vocabulary, mask_token=None)\n",
    "    # Turn the input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    \n",
    "    if use_embedding:\n",
    "        # Create an embedding layer with the specified dimensions.\n",
    "        #embedding_dims = int(6*vocab_size**(1/4))\n",
    "        embedding_dims = EMBEDDING_DIMS\n",
    "        embedding = layers.Embedding(\n",
    "            input_dim=vocab_size+1, output_dim=embedding_dims\n",
    "        )\n",
    "        # Convert the index values to embedding representations.\n",
    "        encoded_feature = embedding(encoded_feature)\n",
    "        encoded_feature = layers.Reshape((embedding_dims, ))(encoded_feature)\n",
    "        #encoded_feature = layers.Activation(\"sigmoid\")(encoded_feature)\n",
    "        \n",
    "    else:\n",
    "        # Create one hot layer\n",
    "        one_hot = layers.experimental.preprocessing.CategoryEncoding(\n",
    "            max_tokens=vocab_size+1, output_mode=\"binary\"\n",
    "        )\n",
    "        # Convert index values to one hot vector.\n",
    "        encoded_feature = one_hot(encoded_feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_inputs(inputs, use_embedding):\n",
    "    encoded_features = []\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            encoded_feature = encode_categorical_feature(inputs[feature_name], feature_name, use_embedding)\n",
    "        elif feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            encoded_feature = encode_numerical_feature(inputs[feature_name], feature_name)\n",
    "        else:\n",
    "            # no encoding for binary features\n",
    "            encoded_feature = inputs[feature_name]\n",
    "        encoded_features.append(encoded_feature)\n",
    "    if len(encoded_features) > 1:\n",
    "        all_features = layers.concatenate(encoded_features, axis=-1)\n",
    "        return all_features\n",
    "    return encoded_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33855dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:58:24.498734Z",
     "iopub.status.busy": "2021-07-21T04:58:24.498039Z",
     "iopub.status.idle": "2021-07-21T04:58:25.138115Z",
     "shell.execute_reply": "2021-07-21T04:58:25.137218Z",
     "shell.execute_reply.started": "2021-07-21T04:26:40.580807Z"
    },
    "id": "d33855dd",
    "outputId": "ba57899f-1c43-4b01-fdf0-fc1fe5a6046d",
    "papermill": {
     "duration": 0.662348,
     "end_time": "2021-07-21T04:58:25.138262",
     "exception": false,
     "start_time": "2021-07-21T04:58:24.475914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset = get_dataset_from_df(val_df, batch_size=BATCH_SIZE)\n",
    "\n",
    "del(val_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8dfcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:58:28.347154Z",
     "iopub.status.busy": "2021-07-21T04:58:26.567580Z",
     "iopub.status.idle": "2021-07-21T04:58:39.248893Z",
     "shell.execute_reply": "2021-07-21T04:58:39.248391Z",
     "shell.execute_reply.started": "2021-07-21T04:26:41.245321Z"
    },
    "id": "caf8dfcc",
    "outputId": "5e6c77f5-49e4-40a2-ed04-1738ec88fe93",
    "papermill": {
     "duration": 14.094722,
     "end_time": "2021-07-21T04:58:39.249040",
     "exception": false,
     "start_time": "2021-07-21T04:58:25.154318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = get_dataset_from_df(train_df, batch_size=BATCH_SIZE)\n",
    "\n",
    "del(train_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e05c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:58:39.288493Z",
     "iopub.status.busy": "2021-07-21T04:58:39.287458Z",
     "iopub.status.idle": "2021-07-21T04:58:39.290447Z",
     "shell.execute_reply": "2021-07-21T04:58:39.289968Z",
     "shell.execute_reply.started": "2021-07-21T04:27:14.000132Z"
    },
    "id": "ff9e05c0",
    "papermill": {
     "duration": 0.025082,
     "end_time": "2021-07-21T04:58:39.290596",
     "exception": false,
     "start_time": "2021-07-21T04:58:39.265514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs, use_embedding=True)\n",
    "    features = layers.Dense(1000, activation=\"relu\")(features)\n",
    "    #features = layers.Dense(64, activation=\"relu\")(features)\n",
    "    outputs = layers.Dense(units=4)(features)\n",
    "\n",
    "    early_stopping = keras.callbacks.EarlyStopping(patience=1)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    #sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=\"adam\", loss=\"MAE\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5046f49a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:58:39.329800Z",
     "iopub.status.busy": "2021-07-21T04:58:39.329110Z",
     "iopub.status.idle": "2021-07-21T04:58:39.331515Z",
     "shell.execute_reply": "2021-07-21T04:58:39.331028Z",
     "shell.execute_reply.started": "2021-07-21T04:27:15.219909Z"
    },
    "id": "5046f49a",
    "papermill": {
     "duration": 0.024917,
     "end_time": "2021-07-21T04:58:39.331686",
     "exception": false,
     "start_time": "2021-07-21T04:58:39.306769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_wide_and_deep_model(hidden_units):\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    wide = encode_inputs(inputs, use_embedding=False)\n",
    "    wide = layers.BatchNormalization()(wide)\n",
    "\n",
    "    deep = encode_inputs(inputs, use_embedding=True)\n",
    "    for units in hidden_units:\n",
    "        deep = layers.Dense(units)(deep)\n",
    "        deep = layers.BatchNormalization()(deep)\n",
    "        deep = layers.ReLU()(deep)\n",
    "        deep = layers.Dropout(0.5)(deep)\n",
    "\n",
    "    merged = layers.concatenate([wide, deep])\n",
    "    outputs = layers.Dense(units=4)(merged)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=\"adam\", loss=\"MAE\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a2664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:58:39.369221Z",
     "iopub.status.busy": "2021-07-21T04:58:39.368224Z",
     "iopub.status.idle": "2021-07-21T04:58:39.369997Z",
     "shell.execute_reply": "2021-07-21T04:58:39.370466Z",
     "shell.execute_reply.started": "2021-07-21T04:27:16.624655Z"
    },
    "id": "dc6a2664",
    "papermill": {
     "duration": 0.0227,
     "end_time": "2021-07-21T04:58:39.370650",
     "exception": false,
     "start_time": "2021-07-21T04:58:39.347950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prev_runs = 0\n",
    "model_name = f\"model_lag1_300bs_v{prev_runs+1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13fff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T04:58:39.405964Z",
     "iopub.status.busy": "2021-07-21T04:58:39.405223Z",
     "iopub.status.idle": "2021-07-21T10:26:00.128906Z",
     "shell.execute_reply": "2021-07-21T10:26:00.143871Z"
    },
    "id": "8c13fff9",
    "outputId": "78db2c05-e2f1-4083-f9b2-26675f4b66cc",
    "papermill": {
     "duration": 19640.757264,
     "end_time": "2021-07-21T10:26:00.144084",
     "exception": false,
     "start_time": "2021-07-21T04:58:39.386820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8148/8148 [==============================] - 1099s 133ms/step - loss: 0.8332 - val_loss: 0.9628\n",
      "Epoch 2/20\n",
      "8148/8148 [==============================] - 1087s 133ms/step - loss: 0.7173 - val_loss: 0.9530\n",
      "Epoch 3/20\n",
      "8148/8148 [==============================] - 1060s 130ms/step - loss: 0.6935 - val_loss: 0.9321\n",
      "Epoch 4/20\n",
      "8148/8148 [==============================] - 1120s 137ms/step - loss: 0.6773 - val_loss: 0.9234\n",
      "Epoch 5/20\n",
      "8148/8148 [==============================] - 1100s 135ms/step - loss: 0.6639 - val_loss: 0.9245\n",
      "Epoch 6/20\n",
      "8148/8148 [==============================] - 1062s 130ms/step - loss: 0.6528 - val_loss: 0.9153\n",
      "Epoch 7/20\n",
      "8148/8148 [==============================] - 1090s 134ms/step - loss: 0.6438 - val_loss: 0.9119\n",
      "Epoch 8/20\n",
      "8148/8148 [==============================] - 1104s 135ms/step - loss: 0.6369 - val_loss: 0.9189\n",
      "Epoch 9/20\n",
      "8148/8148 [==============================] - 1073s 132ms/step - loss: 0.6313 - val_loss: 0.9195\n",
      "Epoch 10/20\n",
      "8148/8148 [==============================] - 1074s 132ms/step - loss: 0.6263 - val_loss: 0.9084\n",
      "Epoch 11/20\n",
      "8148/8148 [==============================] - 1056s 130ms/step - loss: 0.6224 - val_loss: 0.9138\n",
      "Epoch 12/20\n",
      "8148/8148 [==============================] - 1087s 133ms/step - loss: 0.6192 - val_loss: 0.9087\n",
      "Epoch 13/20\n",
      "8148/8148 [==============================] - 1099s 135ms/step - loss: 0.6147 - val_loss: 0.9040\n",
      "Epoch 14/20\n",
      "8148/8148 [==============================] - 1087s 133ms/step - loss: 0.6128 - val_loss: 0.9007\n",
      "Epoch 15/20\n",
      "8148/8148 [==============================] - 1079s 132ms/step - loss: 0.6096 - val_loss: 0.9016\n",
      "Epoch 16/20\n",
      "8148/8148 [==============================] - 1083s 133ms/step - loss: 0.6071 - val_loss: 0.9039\n",
      "Epoch 17/20\n",
      "8148/8148 [==============================] - 1082s 133ms/step - loss: 0.6044 - val_loss: 0.9057\n",
      "Epoch 18/20\n",
      "8148/8148 [==============================] - 1084s 133ms/step - loss: 0.6033 - val_loss: 0.9040\n"
     ]
    }
   ],
   "source": [
    "model = create_wide_and_deep_model([1024, 1024, 1024, 1024])\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=4, restore_best_weights=True)\n",
    "model.fit(train_dataset, epochs=20, validation_data=val_dataset, callbacks=[early_stopping])\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f100536",
   "metadata": {
    "id": "2f100536",
    "papermill": {
     "duration": 34.383942,
     "end_time": "2021-07-21T10:27:08.763936",
     "exception": false,
     "start_time": "2021-07-21T10:26:34.379994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b9cb0",
   "metadata": {
    "id": "d73b9cb0",
    "papermill": {
     "duration": 34.514169,
     "end_time": "2021-07-21T10:28:17.530590",
     "exception": false,
     "start_time": "2021-07-21T10:27:43.016421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pAh-Zb4tcf_f",
   "metadata": {
    "id": "pAh-Zb4tcf_f"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20448.537243,
   "end_time": "2021-07-21T10:28:55.942419",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-21T04:48:07.405176",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
