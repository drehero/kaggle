{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf175acc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-21T11:50:17.830523Z",
     "iopub.status.busy": "2021-07-21T11:50:17.829857Z",
     "iopub.status.idle": "2021-07-21T11:50:17.873785Z",
     "shell.execute_reply": "2021-07-21T11:50:17.873172Z",
     "shell.execute_reply.started": "2021-07-21T11:44:04.786216Z"
    },
    "papermill": {
     "duration": 0.068621,
     "end_time": "2021-07-21T11:50:17.873962",
     "exception": false,
     "start_time": "2021-07-21T11:50:17.805341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mlb-player-salaries/mlbSalaries.csv\n",
      "/kaggle/input/d/drehero/modeltest/model_lag1_300bs_v1/saved_model.pb\n",
      "/kaggle/input/d/drehero/modeltest/model_lag1_300bs_v1/variables/variables.index\n",
      "/kaggle/input/d/drehero/modeltest/model_lag1_300bs_v1/variables/variables.data-00000-of-00001\n",
      "/kaggle/input/mlb-player-digital-engagement-forecasting/players.csv\n",
      "/kaggle/input/mlb-player-digital-engagement-forecasting/example_sample_submission.csv\n",
      "/kaggle/input/mlb-player-digital-engagement-forecasting/teams.csv\n",
      "/kaggle/input/mlb-player-digital-engagement-forecasting/seasons.csv\n",
      "/kaggle/input/mlb-player-digital-engagement-forecasting/example_test.csv\n",
      "/kaggle/input/mlb-player-digital-engagement-forecasting/train_updated.csv\n",
      "/kaggle/input/mlb-player-digital-engagement-forecasting/train.csv\n",
      "/kaggle/input/mlb-player-digital-engagement-forecasting/awards.csv\n",
      "/kaggle/input/mlb-player-digital-engagement-forecasting/mlb/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/mlb-player-digital-engagement-forecasting/mlb/__init__.py\n",
      "/kaggle/input/mlb-social-media-dataset/teams.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cf23b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T11:50:17.903739Z",
     "iopub.status.busy": "2021-07-21T11:50:17.903124Z",
     "iopub.status.idle": "2021-07-21T11:50:23.794198Z",
     "shell.execute_reply": "2021-07-21T11:50:23.793553Z",
     "shell.execute_reply.started": "2021-07-21T11:44:07.097849Z"
    },
    "papermill": {
     "duration": 5.90734,
     "end_time": "2021-07-21T11:50:23.794344",
     "exception": false,
     "start_time": "2021-07-21T11:50:17.887004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlb_preprocessing import *\n",
    "from mlb_config import *\n",
    "\n",
    "import gc\n",
    "import pathlib\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65467f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T11:50:23.822284Z",
     "iopub.status.busy": "2021-07-21T11:50:23.821663Z",
     "iopub.status.idle": "2021-07-21T11:50:23.826494Z",
     "shell.execute_reply": "2021-07-21T11:50:23.825872Z",
     "shell.execute_reply.started": "2021-07-21T11:44:13.634521Z"
    },
    "papermill": {
     "duration": 0.019714,
     "end_time": "2021-07-21T11:50:23.826639",
     "exception": false,
     "start_time": "2021-07-21T11:50:23.806925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = pathlib.Path(\"/kaggle/input\")\n",
    "PATH_TO_MLB_DATA = BASE_DIR / \"mlb-player-digital-engagement-forecasting\"\n",
    "PATH_TO_MODELS = pathlib.Path(\"/kaggle/input/d/drehero/modeltest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8368b34a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T11:50:23.855942Z",
     "iopub.status.busy": "2021-07-21T11:50:23.855002Z",
     "iopub.status.idle": "2021-07-21T11:50:23.858056Z",
     "shell.execute_reply": "2021-07-21T11:50:23.857411Z",
     "shell.execute_reply.started": "2021-07-21T11:44:13.643696Z"
    },
    "papermill": {
     "duration": 0.019254,
     "end_time": "2021-07-21T11:50:23.858189",
     "exception": false,
     "start_time": "2021-07-21T11:50:23.838935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENSEMBLE_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9226062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T11:50:23.895768Z",
     "iopub.status.busy": "2021-07-21T11:50:23.895082Z",
     "iopub.status.idle": "2021-07-21T11:50:23.898736Z",
     "shell.execute_reply": "2021-07-21T11:50:23.898162Z",
     "shell.execute_reply.started": "2021-07-21T11:44:13.654721Z"
    },
    "papermill": {
     "duration": 0.028419,
     "end_time": "2021-07-21T11:50:23.898872",
     "exception": false,
     "start_time": "2021-07-21T11:50:23.870453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lagged_targets_test(sample_submission, historic_targets, player_target_stats, lag):\n",
    "    lagged_targets = pd.DataFrame(sample_submission.loc[:, \"date_playerId\"])\n",
    "    lagged_targets[\"playerId\"] = lagged_targets[\"date_playerId\"].apply(lambda x: x.split(\"_\")[1]).astype(int)\n",
    "    lagged_targets.reset_index(inplace=True)\n",
    "    lagged_targets.rename(columns={\"date\": \"dailyDataDate\"}, inplace=True)\n",
    "    lagged_targets.drop([\"date_playerId\"], axis=1, inplace=True)\n",
    "\n",
    "    earliest_date = int((pd.to_datetime(lagged_targets[\"dailyDataDate\"].min(), format=\"%Y%m%d\") - pd.Timedelta(days=lag)).strftime(\"%Y%m%d\"))\n",
    "\n",
    "    shifted_historic_targets = historic_targets[historic_targets[\"dailyDataDate\"] >= earliest_date].copy()\n",
    "    shifted_historic_targets[\"dailyDataDate\"] = pd.to_datetime(shifted_historic_targets[\"dailyDataDate\"], format=\"%Y%m%d\") + pd.Timedelta(days=lag)\n",
    "    shifted_historic_targets[\"dailyDataDate\"] = shifted_historic_targets[\"dailyDataDate\"].dt.strftime(\"%Y%m%d\").astype(int)\n",
    "\n",
    "    lagged_targets = pd.merge(lagged_targets, shifted_historic_targets, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "\n",
    "    defaults = lagged_targets.loc[:, [\"dailyDataDate\", \"playerId\"]]\n",
    "    target_medians = player_target_stats[[\"playerId\", \"target1_50%\", \"target2_50%\", \"target3_50%\", \"target4_50%\"]].rename(columns={\n",
    "        \"target1_50%\": \"target1\", \"target2_50%\": \"target2\", \"target3_50%\": \"target3\", \"target4_50%\": \"target4\"\n",
    "    })\n",
    "    # TODO: update after changing to yearly stats\n",
    "    defaults = defaults.merge(target_medians, on=[\"playerId\"], how=\"left\")  # use median as a default\n",
    "\n",
    "    mask = lagged_targets.isna()\n",
    "    lagged_targets = lagged_targets.where(~mask, other=defaults.where(mask))\n",
    "\n",
    "    lagged_targets.rename(columns={\n",
    "        \"target1\": f\"target1Lag{lag}\",\n",
    "        \"target2\": f\"target2Lag{lag}\",\n",
    "        \"target3\": f\"target3Lag{lag}\",\n",
    "        \"target4\": f\"target4Lag{lag}\",\n",
    "    }, inplace=True)\n",
    "    return lagged_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e95598b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T11:50:23.928020Z",
     "iopub.status.busy": "2021-07-21T11:50:23.927054Z",
     "iopub.status.idle": "2021-07-21T11:52:28.253935Z",
     "shell.execute_reply": "2021-07-21T11:52:28.254430Z",
     "shell.execute_reply.started": "2021-07-21T11:44:13.940836Z"
    },
    "papermill": {
     "duration": 124.342851,
     "end_time": "2021-07-21T11:52:28.254617",
     "exception": false,
     "start_time": "2021-07-21T11:50:23.911766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep latest rosters and twitter followers in case they are not present in the test set\n",
    "train = pd.read_csv(PATH_TO_MLB_DATA / \"train.csv\")\n",
    "LATEST_ROSTERS = unpack_data(pd.DataFrame(train[~train[\"rosters\"].isna()].iloc[-1, :]).T, [\"rosters\"])[\"rosters\"]\n",
    "LATEST_PLAYER_TWITTER_FOLLOWERS = unpack_data(pd.DataFrame(train[~train[\"playerTwitterFollowers\"].isna()].iloc[-1, :]).T, [\"playerTwitterFollowers\"])[\"playerTwitterFollowers\"]\n",
    "LATEST_TEAM_TWITTER_FOLLOWERS = unpack_data(pd.DataFrame(train[~train[\"teamTwitterFollowers\"].isna()].iloc[-1, :]).T, [\"teamTwitterFollowers\"])[\"teamTwitterFollowers\"]\n",
    "next_day_player_engagement = unpack_data(train, [\"nextDayPlayerEngagement\"])[\"nextDayPlayerEngagement\"]\n",
    "\n",
    "player_target_stats = get_player_target_stats(next_day_player_engagement)\n",
    "historic_targets = next_day_player_engagement.loc[:, [\"dailyDataDate\", \"playerId\", \"target1\", \"target2\", \"target3\", \"target4\"]]\n",
    "\n",
    "del(train, next_day_player_engagement)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3209dd33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T11:52:28.282801Z",
     "iopub.status.busy": "2021-07-21T11:52:28.282146Z",
     "iopub.status.idle": "2021-07-21T11:52:28.317037Z",
     "shell.execute_reply": "2021-07-21T11:52:28.316349Z",
     "shell.execute_reply.started": "2021-07-21T11:46:22.148743Z"
    },
    "papermill": {
     "duration": 0.049893,
     "end_time": "2021-07-21T11:52:28.317184",
     "exception": false,
     "start_time": "2021-07-21T11:52:28.267291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlb_social_media = pd.read_csv(BASE_DIR / \"mlb-social-media-dataset\" / \"teams.csv\")\n",
    "player_salaries = pd.read_csv(BASE_DIR / \"mlb-player-salaries\" / \"mlbSalaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc13134c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T11:52:28.372635Z",
     "iopub.status.busy": "2021-07-21T11:52:28.368393Z",
     "iopub.status.idle": "2021-07-21T11:52:28.375458Z",
     "shell.execute_reply": "2021-07-21T11:52:28.374810Z",
     "shell.execute_reply.started": "2021-07-21T11:46:22.182531Z"
    },
    "papermill": {
     "duration": 0.045499,
     "end_time": "2021-07-21T11:52:28.375608",
     "exception": false,
     "start_time": "2021-07-21T11:52:28.330109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_test(unpacked_data, sample_submission, seasons, teams, players, player_target_stats, mlb_social_media, player_salaries, historic_targets):\n",
    "    global LATEST_PLAYER_TWITTER_FOLLOWERS\n",
    "    global LATEST_TEAM_TWITTER_FOLLOWERS\n",
    "    global LATEST_ROSTERS\n",
    "    df = sample_submission.copy()\n",
    "    # date\n",
    "    df[\"playerId\"] = df[\"date_playerId\"].apply(lambda x: int(x.split(\"_\")[1]))\n",
    "    df[\"dailyDataDate\"] = sample_submission.index\n",
    "    dates_with_info = get_dates_with_info(df, seasons)\n",
    "    df = df.merge(dates_with_info, on=\"dailyDataDate\", how=\"left\")\n",
    "    # players\n",
    "    players_to_merge = prepare_players(players)\n",
    "    df = df.merge(players_to_merge, on=\"playerId\", how=\"left\")\n",
    "    # rosters\n",
    "    rosters_to_merge = prepare_rosters(unpacked_data[\"rosters\"])\n",
    "    if rosters_to_merge.empty:\n",
    "        rosters_to_merge = prepare_rosters(LATEST_ROSTERS)\n",
    "        rosters_to_merge[\"dailyDataDate\"] = df[\"dailyDataDate\"].max()\n",
    "    elif LATEST_ROSTERS[\"dailyDataDate\"].max() < unpacked_data[\"rosters\"][\"dailyDataDate\"].max():\n",
    "        LATEST_ROSTERS = unpacked_data[\"rosters\"]\n",
    "    df = df.merge(rosters_to_merge, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "    # teams\n",
    "    teams_to_merge = prepare_teams(teams)\n",
    "    df = df.merge(teams_to_merge, on=[\"teamId\"], how=\"left\")\n",
    "    # games\n",
    "    if unpacked_data[\"games\"].empty:\n",
    "        games_to_merge = pd.DataFrame(columns=GAMES_TO_MERGE_COLUMNS)\n",
    "        games_to_merge[[\"dailyDataDate\", \"teamId\"]] = df[[\"dailyDataDate\", \"teamId\"]]\n",
    "    else:\n",
    "        games_to_merge = prepare_games(unpacked_data[\"games\"])\n",
    "    df = df.merge(games_to_merge, on=[\"dailyDataDate\", \"teamId\"], how=\"left\")\n",
    "    # team box scores\n",
    "    #if unpacked_data[\"teamBoxScores\"].empty:\n",
    "    #    team_box_scores_to_merge = pd.DataFrame(columns=TEAM_BOX_SCORES_TO_MERGE_COLUMNS)\n",
    "    #    team_box_scores_to_merge[[\"dailyDataDate\", \"teamId\"]] = df[[\"dailyDataDate\", \"teamId\"]]\n",
    "    #else:\n",
    "    #    team_box_scores_to_merge = prepare_team_box_scores(unpacked_data[\"teamBoxScores\"])\n",
    "    #df = df.merge(team_box_scores_to_merge, on=[\"dailyDataDate\", \"teamId\"], how=\"left\")\n",
    "    # player box scores\n",
    "    if unpacked_data[\"playerBoxScores\"].empty:\n",
    "        player_box_scores_to_merge = pd.DataFrame(columns=PLAYER_BOX_SCORES_TO_MERGE_COLUMNS)\n",
    "        player_box_scores_to_merge[[\"dailyDataDate\", \"playerId\"]] = df[[\"dailyDataDate\", \"playerId\"]]\n",
    "    else:\n",
    "        player_box_scores_to_merge = prepare_player_box_scores(unpacked_data[\"playerBoxScores\"])\n",
    "    df = df.merge(player_box_scores_to_merge, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "    # transactions\n",
    "    if unpacked_data[\"transactions\"].empty:\n",
    "        transactions_to_merge = pd.DataFrame(columns=TRANSACTIONS_TO_MERGE_COLUMNS)\n",
    "        transactions_to_merge[[\"dailyDataDate\", \"playerId\"]] = df[[\"dailyDataDate\", \"playerId\"]]\n",
    "    else:\n",
    "        transactions_to_merge = prepare_transactions(unpacked_data[\"transactions\"])\n",
    "    df = df.merge(transactions_to_merge, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "    # awards\n",
    "    if unpacked_data[\"awards\"].empty:\n",
    "        awards_to_merge = pd.DataFrame(columns=AWARDS_TO_MERGE_COLUMNS)\n",
    "        awards_to_merge[[\"dailyDataDate\", \"playerId\"]] = df[[\"dailyDataDate\", \"playerId\"]]\n",
    "    else:\n",
    "        awards_to_merge = prepare_awards(unpacked_data[\"awards\"])\n",
    "    df = df.merge(awards_to_merge, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "    # events\n",
    "    if unpacked_data[\"events\"].empty or unpacked_data[\"games\"].empty:\n",
    "        events_to_merge = pd.DataFrame(columns=EVENTS_TO_MERGE_COLUMNS)\n",
    "        events_to_merge[[\"dailyDataDate\", \"playerId\"]] = df[[\"dailyDataDate\", \"playerId\"]]\n",
    "    else:\n",
    "        events_to_merge = prepare_events(unpacked_data[\"events\"], unpacked_data[\"games\"])\n",
    "    df = df.merge(events_to_merge, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "    # standings\n",
    "    if unpacked_data[\"standings\"].empty:\n",
    "        standings_to_merge = pd.DataFrame(columns=STANDINGS_TO_MERGE_COLUMNS)\n",
    "        standings_to_merge[[\"dailyDataDate\", \"teamId\"]] = df[[\"dailyDataDate\", \"teamId\"]]\n",
    "    else:\n",
    "        standings_to_merge = prepare_standings(unpacked_data[\"standings\"])\n",
    "    df = df.merge(standings_to_merge, on=[\"dailyDataDate\", \"teamId\"], how=\"left\")\n",
    "    # twitter\n",
    "    player_twitter_followers = unpacked_data[\"playerTwitterFollowers\"].copy()\n",
    "    if player_twitter_followers.empty:\n",
    "        player_twitter_followers = LATEST_PLAYER_TWITTER_FOLLOWERS.copy()\n",
    "        player_twitter_followers[\"date\"] = df[\"date\"].max()\n",
    "    elif LATEST_PLAYER_TWITTER_FOLLOWERS[\"date\"].max() < player_twitter_followers[\"date\"].max():\n",
    "        LATEST_PLAYER_TWITTER_FOLLOWERS = player_twitter_followers.copy()\n",
    "    df = pd.merge_asof(df, player_twitter_followers.loc[:, ('date', 'playerId', 'numberOfFollowers')].rename(\n",
    "        columns={\"numberOfFollowers\": \"numberOfFollowersPlayer\"}), on=\"date\", by=\"playerId\", direction=\"backward\")\n",
    "    team_twitter_followers = unpacked_data[\"teamTwitterFollowers\"].copy()\n",
    "    if team_twitter_followers.empty:\n",
    "        team_twitter_followers = LATEST_TEAM_TWITTER_FOLLOWERS.copy()\n",
    "        team_twitter_followers[\"date\"] = df[\"date\"].max()\n",
    "    elif LATEST_TEAM_TWITTER_FOLLOWERS[\"date\"].max() < team_twitter_followers[\"date\"].max():\n",
    "        LATEST_TEAM_TWITTER_FOLLOWERS = team_twitter_followers.copy()\n",
    "    team_twitter_followers[\"teamId\"] = team_twitter_followers[\"teamId\"].astype(str)\n",
    "    df = pd.merge_asof(df, team_twitter_followers.loc[:, (\"date\", \"teamId\", \"numberOfFollowers\")].rename(\n",
    "        columns={\"numberOfFollowers\": \"numberOfFollowersTeam\"}), on=\"date\", by=\"teamId\", direction=\"backward\")\n",
    "    # player target stats\n",
    "    #df = df.merge(player_target_stats, on=\"playerId\", how=\"left\")\n",
    "    # mlb social media\n",
    "    mlb_social_media = prepare_mlb_social_media(mlb_social_media)\n",
    "    df = df.merge(mlb_social_media, on=\"teamId\", how=\"left\")\n",
    "    # player salaries\n",
    "    player_salaries_to_merge = prepare_player_salaries(player_salaries, players)\n",
    "    df = df.merge(player_salaries_to_merge, on=[\"playerId\", \"year\"], how=\"left\")\n",
    "    # lagged targets\n",
    "    for lag in range(1, N_LAGS+1):\n",
    "        lagged_targets = get_lagged_targets_test(sample_submission, historic_targets, player_target_stats, lag)\n",
    "        df = df.merge(lagged_targets, on=[\"dailyDataDate\", \"playerId\"], how=\"left\")\n",
    "\n",
    "    df.fillna(COLUMN_DEFAULTS, inplace=True)\n",
    "    for feature_name in df.columns:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            df[feature_name] = df[feature_name].astype(str)\n",
    "    return df[FEATURE_NAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c69a7928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T11:52:28.406188Z",
     "iopub.status.busy": "2021-07-21T11:52:28.405434Z",
     "iopub.status.idle": "2021-07-21T11:52:28.440436Z",
     "shell.execute_reply": "2021-07-21T11:52:28.441029Z",
     "shell.execute_reply.started": "2021-07-21T11:46:22.213740Z"
    },
    "papermill": {
     "duration": 0.052809,
     "end_time": "2021-07-21T11:52:28.441206",
     "exception": false,
     "start_time": "2021-07-21T11:52:28.388397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seasons = pd.read_csv(PATH_TO_MLB_DATA / \"seasons.csv\")\n",
    "players = pd.read_csv(PATH_TO_MLB_DATA / \"players.csv\")\n",
    "teams = pd.read_csv(PATH_TO_MLB_DATA / \"teams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcf0e49a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T11:52:28.469445Z",
     "iopub.status.busy": "2021-07-21T11:52:28.468818Z",
     "iopub.status.idle": "2021-07-21T11:52:28.474958Z",
     "shell.execute_reply": "2021-07-21T11:52:28.474465Z",
     "shell.execute_reply.started": "2021-07-21T11:46:22.263958Z"
    },
    "papermill": {
     "duration": 0.021166,
     "end_time": "2021-07-21T11:52:28.475093",
     "exception": false,
     "start_time": "2021-07-21T11:52:28.453927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_historic_targets(historic_targets, submission):\n",
    "    predicted_targets = submission.copy()\n",
    "    predicted_targets[\"dailyDataDate\"] = predicted_targets.index\n",
    "    predicted_targets[\"playerId\"] = predicted_targets[\"date_playerId\"].apply(lambda x: x.split(\"_\")[1]).astype(int)\n",
    "    historic_targets = historic_targets.append(predicted_targets[[\"dailyDataDate\", \"playerId\"] + TARGET_FEATURE_NAMES])\n",
    "    historic_targets = historic_targets.drop_duplicates(subset=[\"dailyDataDate\", \"playerId\"], keep=\"last\")\n",
    "    return historic_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed6b69a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T11:52:28.507151Z",
     "iopub.status.busy": "2021-07-21T11:52:28.506178Z",
     "iopub.status.idle": "2021-07-21T11:52:28.509955Z",
     "shell.execute_reply": "2021-07-21T11:52:28.510438Z",
     "shell.execute_reply.started": "2021-07-21T11:46:22.275067Z"
    },
    "papermill": {
     "duration": 0.022857,
     "end_time": "2021-07-21T11:52:28.510602",
     "exception": false,
     "start_time": "2021-07-21T11:52:28.487745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexample_test = pd.read_csv(PATH_TO_MLB_DATA / \"example_test.csv\")\\nexample_sample_submission = pd.read_csv(PATH_TO_MLB_DATA / \"example_sample_submission.csv\")\\n\\nexample_test.set_index(\"date\", inplace=True)\\nexample_sample_submission.set_index(\"date\", inplace=True)\\n\\nunpacked_test = unpack_data(example_test, TEST_FEATURE_NAMES, is_test=True)\\ntest_df = prepare_test(unpacked_test, example_sample_submission, seasons, teams, players,\\n                       player_target_stats, mlb_social_media, player_salaries, historic_targets)\\nX = get_dataset_from_df(test_df, batch_size=BATCH_SIZE, is_test=True)\\n\\nmodel = keras.models.load_model(PATH_TO_MODELS / \"model_lag1_300bs_v1\")\\ny_pred = model.predict(X)\\n#for i in range(2, ENSEMBLE_SIZE+1):\\n#    model = keras.models.load_model(PATH_TO_MODELS / f\"model_{i}\")\\n#    y_pred += model.predict(X)\\n    \\nexample_sample_submission[TARGET_FEATURE_NAMES] = y_pred #/ ENSEMBLE_SIZE\\nexample_sample_submission\\n#'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "example_test = pd.read_csv(PATH_TO_MLB_DATA / \"example_test.csv\")\n",
    "example_sample_submission = pd.read_csv(PATH_TO_MLB_DATA / \"example_sample_submission.csv\")\n",
    "\n",
    "example_test.set_index(\"date\", inplace=True)\n",
    "example_sample_submission.set_index(\"date\", inplace=True)\n",
    "\n",
    "unpacked_test = unpack_data(example_test, TEST_FEATURE_NAMES, is_test=True)\n",
    "test_df = prepare_test(unpacked_test, example_sample_submission, seasons, teams, players,\n",
    "                       player_target_stats, mlb_social_media, player_salaries, historic_targets)\n",
    "X = get_dataset_from_df(test_df, batch_size=BATCH_SIZE, is_test=True)\n",
    "\n",
    "model = keras.models.load_model(PATH_TO_MODELS / \"model_lag1_300bs_v1\")\n",
    "y_pred = model.predict(X)\n",
    "#for i in range(2, ENSEMBLE_SIZE+1):\n",
    "#    model = keras.models.load_model(PATH_TO_MODELS / f\"model_{i}\")\n",
    "#    y_pred += model.predict(X)\n",
    "    \n",
    "example_sample_submission[TARGET_FEATURE_NAMES] = y_pred #/ ENSEMBLE_SIZE\n",
    "example_sample_submission\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a02d2624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-21T11:52:28.540519Z",
     "iopub.status.busy": "2021-07-21T11:52:28.539562Z",
     "iopub.status.idle": "2021-07-21T11:56:03.887939Z",
     "shell.execute_reply": "2021-07-21T11:56:03.886863Z",
     "shell.execute_reply.started": "2021-07-21T11:46:22.291369Z"
    },
    "papermill": {
     "duration": 215.364663,
     "end_time": "2021-07-21T11:56:03.888314",
     "exception": false,
     "start_time": "2021-07-21T11:52:28.523651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "import mlb\n",
    "\n",
    "env = mlb.make_env()\n",
    "iter_test = env.iter_test()\n",
    "\n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    unpacked_test = unpack_data(test_df, TEST_FEATURE_NAMES, is_test=True)\n",
    "    X_df = prepare_test(unpacked_test, sample_prediction_df, seasons, teams, players, player_target_stats,\n",
    "                        mlb_social_media, player_salaries, historic_targets)\n",
    "    X = get_dataset_from_df(X_df, batch_size=BATCH_SIZE, is_test=True)\n",
    "    \n",
    "    model = keras.models.load_model(PATH_TO_MODELS / \"model_lag1_300bs_v1\")\n",
    "    y_pred = model.predict(X)\n",
    "    #for i in range(2, ENSEMBLE_SIZE+1):\n",
    "    #    model = keras.models.load_model(PATH_TO_MODELS / f\"model_{i}\")\n",
    "    #    y_pred += model.predict(X)\n",
    "    sample_prediction_df[TARGET_FEATURE_NAMES] = y_pred #/ ENSEMBLE_SIZE\n",
    "    sample_prediction_df[TARGET_FEATURE_NAMES] = sample_prediction_df[TARGET_FEATURE_NAMES].clip(0, 100)\n",
    "    sample_prediction_df = sample_prediction_df.fillna(0)\n",
    "    \n",
    "    # TODO make sure to use different historic targets in ensemble\n",
    "    historic_targets = update_historic_targets(historic_targets, sample_prediction_df)\n",
    "\n",
    "    # Submit predictions\n",
    "    env.predict(sample_prediction_df)  # constructs submissions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c54f5",
   "metadata": {
    "papermill": {
     "duration": 0.013723,
     "end_time": "2021-07-21T11:56:03.918732",
     "exception": false,
     "start_time": "2021-07-21T11:56:03.905009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 357.216758,
   "end_time": "2021-07-21T11:56:06.644230",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-21T11:50:09.427472",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
