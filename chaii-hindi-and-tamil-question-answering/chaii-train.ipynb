{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T18:31:40.613331Z",
     "iopub.status.busy": "2021-10-16T18:31:40.612905Z",
     "iopub.status.idle": "2021-10-16T18:31:49.123140Z",
     "shell.execute_reply": "2021-10-16T18:31:49.122201Z",
     "shell.execute_reply.started": "2021-10-16T18:31:40.613216Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 18:31:41.228752: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2021-10-16 18:31:41.228881: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from transformers import AutoTokenizer, TFRobertaForQuestionAnswering, TFBertForQuestionAnswering\n",
    "from sklearn import model_selection\n",
    "\n",
    "from chaii_config import *\n",
    "from chaii_models import *\n",
    "from chaii_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T18:31:51.327486Z",
     "iopub.status.busy": "2021-10-16T18:31:51.327005Z",
     "iopub.status.idle": "2021-10-16T18:31:51.331942Z",
     "shell.execute_reply": "2021-10-16T18:31:51.331002Z",
     "shell.execute_reply.started": "2021-10-16T18:31:51.327430Z"
    }
   },
   "outputs": [],
   "source": [
    "FOLD = 4\n",
    "MODEL_CONFIG = muril_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T18:31:51.880460Z",
     "iopub.status.busy": "2021-10-16T18:31:51.879841Z",
     "iopub.status.idle": "2021-10-16T18:31:51.903727Z",
     "shell.execute_reply": "2021-10-16T18:31:51.902395Z",
     "shell.execute_reply.started": "2021-10-16T18:31:51.880407Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_train_features(examples_df, tokenizer, config):\n",
    "    examples = examples_df.copy().reset_index(drop=True)\n",
    "    \n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if config[\"pad_on_right\"] else \"context\"].to_list(),\n",
    "        examples[\"context\" if config[\"pad_on_right\"] else \"question\"].to_list(),\n",
    "        truncation=\"only_second\" if config[\"pad_on_right\"] else \"only_first\",\n",
    "        max_length=config[\"max_length\"],\n",
    "        stride=config[\"doc_stride\"],\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        return_token_type_ids=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Example to feature mapping as long contexts might give multiple features\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # Character to token mapping\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Get labels\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Sequence ids indicate from which sequence a token is\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        sample_index = sample_mapping[i]  # which example created this feature\n",
    "        answer_text = examples[\"answer_text\"].values[sample_index]\n",
    "        answer_start_char = examples[\"answer_start\"].values[sample_index]\n",
    "        answer_end_char = answer_start_char + len(answer_text)\n",
    "\n",
    "        # Find start and end token index (set default to cls index)\n",
    "        answer_start_token = cls_index\n",
    "        answer_end_token = cls_index\n",
    "\n",
    "        # Get start and end of context\n",
    "        token_start_index = 0\n",
    "        while sequence_ids[token_start_index] != (1 if config[\"pad_on_right\"] else 0):\n",
    "            token_start_index += 1\n",
    "        token_end_index = len(input_ids) - 1\n",
    "        while sequence_ids[token_end_index] != (1 if config[\"pad_on_right\"] else 0):\n",
    "            token_end_index -= 1\n",
    "\n",
    "        # Detect if the answer is inside the span (otherwise use leave cls label)\n",
    "        if (offsets[token_start_index][0] <= answer_start_char and offsets[token_end_index][1] >= answer_end_char):\n",
    "            while token_start_index < len(offsets) and offsets[token_start_index][0] <= answer_start_char:\n",
    "                token_start_index += 1\n",
    "            answer_start_token = token_start_index - 1\n",
    "            while offsets[token_end_index][1] >= answer_end_char:\n",
    "                token_end_index -= 1\n",
    "            answer_end_token = token_end_index + 1\n",
    "\n",
    "        if answer_start_token == cls_index or answer_end_token == cls_index:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            tokenized_examples[\"start_positions\"].append(answer_start_token)\n",
    "            tokenized_examples[\"end_positions\"].append(answer_end_token)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T18:31:52.352105Z",
     "iopub.status.busy": "2021-10-16T18:31:52.351788Z",
     "iopub.status.idle": "2021-10-16T18:31:52.359954Z",
     "shell.execute_reply": "2021-10-16T18:31:52.358817Z",
     "shell.execute_reply.started": "2021-10-16T18:31:52.352073Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model_input(tokenized_features, is_train=True):\n",
    "    if is_train:\n",
    "        X_train = [\n",
    "            np.array(tokenized_features[\"input_ids\"]),\n",
    "            np.array(tokenized_features[\"attention_mask\"]),\n",
    "            np.array(tokenized_features[\"token_type_ids\"]),\n",
    "        ]\n",
    "        Y_train = [\n",
    "            np.array(tokenized_features[\"start_positions\"]),\n",
    "            np.array(tokenized_features[\"end_positions\"]),\n",
    "        ]\n",
    "        return X_train, Y_train\n",
    "    else:\n",
    "        X_test = [\n",
    "            np.array(tokenized_features[\"input_ids\"]),\n",
    "            np.array(tokenized_features[\"attention_mask\"]),\n",
    "            np.array(tokenized_features[\"token_type_ids\"]),\n",
    "        ]\n",
    "        return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T18:31:53.218008Z",
     "iopub.status.busy": "2021-10-16T18:31:53.217671Z",
     "iopub.status.idle": "2021-10-16T18:31:54.947360Z",
     "shell.execute_reply": "2021-10-16T18:31:54.946262Z",
     "shell.execute_reply.started": "2021-10-16T18:31:53.217976Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CONFIG[\"model_checkpoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T18:31:54.949283Z",
     "iopub.status.busy": "2021-10-16T18:31:54.949027Z",
     "iopub.status.idle": "2021-10-16T18:31:56.218471Z",
     "shell.execute_reply": "2021-10-16T18:31:56.217568Z",
     "shell.execute_reply.started": "2021-10-16T18:31:54.949254Z"
    }
   },
   "outputs": [],
   "source": [
    "chaii = pd.read_csv(INPUT_DIR / \"chaii-hindi-and-tamil-question-answering/train.csv\")\n",
    "mlqa = pd.read_csv(INPUT_DIR / \"chaii-data/mlqa.csv\")\n",
    "xquad = pd.read_csv(INPUT_DIR / \"chaii-data/xquad.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T18:31:56.222421Z",
     "iopub.status.busy": "2021-10-16T18:31:56.222164Z",
     "iopub.status.idle": "2021-10-16T18:31:56.282196Z",
     "shell.execute_reply": "2021-10-16T18:31:56.281283Z",
     "shell.execute_reply.started": "2021-10-16T18:31:56.222391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>language</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>903deec17</td>\n",
       "      <td>ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...</td>\n",
       "      <td>மனித உடலில் எத்தனை எலும்புகள் உள்ளன?</td>\n",
       "      <td>206</td>\n",
       "      <td>53</td>\n",
       "      <td>tamil</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d9841668c</td>\n",
       "      <td>காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...</td>\n",
       "      <td>காளிதாசன் எங்கு பிறந்தார்?</td>\n",
       "      <td>காசுமீரில்</td>\n",
       "      <td>2358</td>\n",
       "      <td>tamil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29d154b56</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...</td>\n",
       "      <td>பென்சிலின் கண்டுபிடித்தவர் யார்?</td>\n",
       "      <td>சர் அலெக்ஸாண்டர் ஃபிளெமிங்</td>\n",
       "      <td>0</td>\n",
       "      <td>tamil</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41660850a</td>\n",
       "      <td>குழந்தையின் அழுகையை  நிறுத்தவும், தூங்க வைக்கவ...</td>\n",
       "      <td>தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...</td>\n",
       "      <td>தாலாட்டு</td>\n",
       "      <td>68</td>\n",
       "      <td>tamil</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b29c82c22</td>\n",
       "      <td>சூரியக் குடும்பம் \\nசூரியக் குடும்பம் (Solar S...</td>\n",
       "      <td>பூமியின் அருகில் உள்ள விண்மீன் எது?</td>\n",
       "      <td>சூரியனும்</td>\n",
       "      <td>585</td>\n",
       "      <td>tamil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7724</th>\n",
       "      <td>57378c9b1c456719005744aa</td>\n",
       "      <td>विद्युत आवेश के परिवर्तन की समय दर के रूप में ...</td>\n",
       "      <td>इलेक्ट्रोस्टैटिक और चुंबकीय बल के योग के रूप क...</td>\n",
       "      <td>इलेक्ट्रोस्टैटिक बल</td>\n",
       "      <td>328</td>\n",
       "      <td>hindi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7725</th>\n",
       "      <td>5737a25ac3c5551400e51f51</td>\n",
       "      <td>उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...</td>\n",
       "      <td>संरचनाओं में तनाव का कारण क्या बनता है?</td>\n",
       "      <td>तनाव टेंसर</td>\n",
       "      <td>343</td>\n",
       "      <td>hindi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7726</th>\n",
       "      <td>5737a25ac3c5551400e51f52</td>\n",
       "      <td>उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...</td>\n",
       "      <td>किसी वस्तु के आयतन में क्रॉस सेक्शन क्षेत्र की...</td>\n",
       "      <td>दबाव की शर्तें</td>\n",
       "      <td>118</td>\n",
       "      <td>hindi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7727</th>\n",
       "      <td>5737a25ac3c5551400e51f53</td>\n",
       "      <td>उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...</td>\n",
       "      <td>सामान्य ताकतों से क्या जुड़ा है?</td>\n",
       "      <td>दबाव की शर्तें</td>\n",
       "      <td>118</td>\n",
       "      <td>hindi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7728</th>\n",
       "      <td>5737a25ac3c5551400e51f54</td>\n",
       "      <td>उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...</td>\n",
       "      <td>आयतन में क्षेत्र की गणना करते समय दबाव की क्या...</td>\n",
       "      <td>नियम-निष्ठता</td>\n",
       "      <td>101</td>\n",
       "      <td>hindi</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7729 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0                    903deec17   \n",
       "1                    d9841668c   \n",
       "2                    29d154b56   \n",
       "3                    41660850a   \n",
       "4                    b29c82c22   \n",
       "...                        ...   \n",
       "7724  57378c9b1c456719005744aa   \n",
       "7725  5737a25ac3c5551400e51f51   \n",
       "7726  5737a25ac3c5551400e51f52   \n",
       "7727  5737a25ac3c5551400e51f53   \n",
       "7728  5737a25ac3c5551400e51f54   \n",
       "\n",
       "                                                context  \\\n",
       "0     ஒரு சாதாரண வளர்ந்த மனிதனுடைய எலும்புக்கூடு பின...   \n",
       "1     காளிதாசன் (தேவநாகரி: कालिदास) சமஸ்கிருத இலக்கி...   \n",
       "2     சர் அலெக்ஸாண்டர் ஃபிளெமிங் (Sir Alexander Flem...   \n",
       "3     குழந்தையின் அழுகையை  நிறுத்தவும், தூங்க வைக்கவ...   \n",
       "4     சூரியக் குடும்பம் \\nசூரியக் குடும்பம் (Solar S...   \n",
       "...                                                 ...   \n",
       "7724  विद्युत आवेश के परिवर्तन की समय दर के रूप में ...   \n",
       "7725  उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...   \n",
       "7726  उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...   \n",
       "7727  उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...   \n",
       "7728  उस आयतन के लिए प्रासंगिक क्रॉस-सेक्शनल क्षेत्र...   \n",
       "\n",
       "                                               question  \\\n",
       "0                  மனித உடலில் எத்தனை எலும்புகள் உள்ளன?   \n",
       "1                            காளிதாசன் எங்கு பிறந்தார்?   \n",
       "2                      பென்சிலின் கண்டுபிடித்தவர் யார்?   \n",
       "3     தமிழ்நாட்டில் குழந்தைகளை தூங்க வைக்க பாடும் பா...   \n",
       "4                   பூமியின் அருகில் உள்ள விண்மீன் எது?   \n",
       "...                                                 ...   \n",
       "7724  इलेक्ट्रोस्टैटिक और चुंबकीय बल के योग के रूप क...   \n",
       "7725            संरचनाओं में तनाव का कारण क्या बनता है?   \n",
       "7726  किसी वस्तु के आयतन में क्रॉस सेक्शन क्षेत्र की...   \n",
       "7727                    सामान्य ताकतों से क्या जुड़ा है?   \n",
       "7728  आयतन में क्षेत्र की गणना करते समय दबाव की क्या...   \n",
       "\n",
       "                     answer_text  answer_start language  kfold  \n",
       "0                            206            53    tamil      4  \n",
       "1                     காசுமீரில்          2358    tamil      1  \n",
       "2     சர் அலெக்ஸாண்டர் ஃபிளெமிங்             0    tamil      3  \n",
       "3                       தாலாட்டு            68    tamil      3  \n",
       "4                      சூரியனும்           585    tamil      1  \n",
       "...                          ...           ...      ...    ...  \n",
       "7724         इलेक्ट्रोस्टैटिक बल           328    hindi      4  \n",
       "7725                  तनाव टेंसर           343    hindi      3  \n",
       "7726              दबाव की शर्तें           118    hindi      2  \n",
       "7727              दबाव की शर्तें           118    hindi      1  \n",
       "7728                नियम-निष्ठता           101    hindi      4  \n",
       "\n",
       "[7729 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([chaii, mlqa, xquad]).reset_index(drop=True)\n",
    "df[\"kfold\"] = -1\n",
    "kf = model_selection.StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=1)\n",
    "for fold, (t, v) in enumerate(kf.split(X=df, y=df.language.values)):\n",
    "    df.loc[v, \"kfold\"] = fold\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T18:31:56.285037Z",
     "iopub.status.busy": "2021-10-16T18:31:56.284514Z",
     "iopub.status.idle": "2021-10-16T18:32:53.130504Z",
     "shell.execute_reply": "2021-10-16T18:32:53.129563Z",
     "shell.execute_reply.started": "2021-10-16T18:31:56.284990Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 18:31:56.293391: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-16 18:31:56.296471: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2021-10-16 18:31:56.296514: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-16 18:31:56.296541: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c47c18d74a1d): /proc/driver/nvidia/version does not exist\n",
      "2021-10-16 18:31:56.300098: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-16 18:31:56.302090: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-16 18:31:56.339149: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2021-10-16 18:31:56.339228: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30181}\n",
      "2021-10-16 18:31:56.356665: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2021-10-16 18:31:56.356727: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30181}\n",
      "2021-10-16 18:31:56.358219: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30181\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForQuestionAnswering: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 504857600   input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "start_logit (Dense)             (None, 384, 1)       1024        bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "end_logit (Dense)               (None, 384, 1)       1024        bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 504,859,648\n",
      "Trainable params: 504,859,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if USE_TPU:\n",
    "    # Create distribution strategy\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    with strategy.scope():\n",
    "        model = create_model(MODEL_CONFIG)\n",
    "else:\n",
    "    model = create_model(MODEL_CONFIG)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T18:32:53.132335Z",
     "iopub.status.busy": "2021-10-16T18:32:53.132085Z",
     "iopub.status.idle": "2021-10-16T18:32:53.164818Z",
     "shell.execute_reply": "2021-10-16T18:32:53.163680Z",
     "shell.execute_reply.started": "2021-10-16T18:32:53.132306Z"
    }
   },
   "outputs": [],
   "source": [
    "class ExactMatch(keras.callbacks.Callback):\n",
    "    def __init__(self, eval_df, eval_features, tokenizer):\n",
    "        self.eval_df = eval_df\n",
    "        self.eval_features = eval_features\n",
    "        self.tokenizer = tokenizer\n",
    "        self.x_eval = [\n",
    "            np.array(eval_features[\"input_ids\"]),\n",
    "            np.array(eval_features[\"attention_mask\"]),\n",
    "            np.array(eval_features[\"token_type_ids\"]),\n",
    "        ]\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        raw_predictions = self.model.predict(self.x_eval)\n",
    "        final_predictions = postprocess_predictions(\n",
    "            self.eval_df, self.eval_features, raw_predictions, self.tokenizer, verbose=False\n",
    "        )\n",
    "        results = pd.DataFrame(\n",
    "            {\n",
    "                \"id\": self.eval_df[\"id\"].values,\n",
    "                \"language\": self.eval_df[\"language\"].values,\n",
    "                \"answer\": self.eval_df[\"answer_text\"].values,\n",
    "            }\n",
    "        )\n",
    "        results[\"prediction\"] = results[\"id\"].apply(lambda x: final_predictions[x])\n",
    "        results[\"exact_match\"] = results[\"prediction\"] == results[\"answer\"]\n",
    "        acc = sum(results[\"exact_match\"] / results.shape[0])\n",
    "        if results[\"language\"].nunique() > 1:\n",
    "            results_hindi = results[results[\"language\"] == \"hindi\"]\n",
    "            results_tamil = results[results[\"language\"] == \"tamil\"]\n",
    "            acc_hindi = sum(results_hindi[\"prediction\"] == results_hindi[\"answer\"]) / results_hindi.shape[0]\n",
    "            acc_tamil = sum(results_tamil[\"prediction\"] == results_tamil[\"answer\"]) / results_tamil.shape[0]\n",
    "            print(\n",
    "                f\"\\nepoch={epoch+1}, exact match score={acc:.2f},\",\n",
    "                f\"exact match score (hindi)={acc_hindi:.2f},\",\n",
    "                f\"exact match score (tamil)={acc_tamil:.2f}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}\")\n",
    "        \n",
    "        \n",
    "class JaccardSimilarity(keras.callbacks.Callback):\n",
    "    def __init__(self, eval_df, eval_features, tokenizer):\n",
    "        self.eval_df = eval_df\n",
    "        self.eval_features = eval_features\n",
    "        self.tokenizer = tokenizer\n",
    "        self.x_eval = [\n",
    "            np.array(eval_features[\"input_ids\"]),\n",
    "            np.array(eval_features[\"attention_mask\"]),\n",
    "            np.array(eval_features[\"token_type_ids\"]),\n",
    "        ]\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        raw_predictions = self.model.predict(self.x_eval)\n",
    "        final_predictions = postprocess_predictions(\n",
    "            self.eval_df, self.eval_features, raw_predictions, self.tokenizer, verbose=False\n",
    "        )\n",
    "        results = pd.DataFrame(\n",
    "            {\n",
    "                \"id\": self.eval_df[\"id\"].values,\n",
    "                \"language\": self.eval_df[\"language\"].values,\n",
    "                \"answer\": self.eval_df[\"answer_text\"].values,\n",
    "            }\n",
    "        )\n",
    "        results[\"prediction\"] = results[\"id\"].apply(lambda x: final_predictions[x])\n",
    "        results[\"jaccard\"] = results[[\"answer\", \"prediction\"]].apply(lambda x: jaccard_similarity(x[0], x[1]), axis=1)\n",
    "        jaccard_sim = results[\"jaccard\"].mean()\n",
    "        if results[\"language\"].nunique() > 1:\n",
    "            jaccard_sim_hindi = results.loc[results[\"language\"] == \"hindi\", \"jaccard\"].mean()\n",
    "            jaccard_sim_tamil = results.loc[results[\"language\"] == \"tamil\", \"jaccard\"].mean()\n",
    "            print(\n",
    "                f\"\\nepoch={epoch+1}, jaccard similarity={jaccard_sim:.2f},\",\n",
    "                f\"jaccard similarity (hindi)={jaccard_sim_hindi:.2f},\",\n",
    "                f\"jaccard similarity (tamil)={jaccard_sim_tamil:.2f}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"\\nepoch={epoch+1}, jaccard similarity={jaccard_sim:.2f}\")\n",
    "            \n",
    "            \n",
    "class EarlyStoppingAtMaxJaccardSimilarity(keras.callbacks.Callback):\n",
    "    \"\"\"Stop training when the Jaccard Similarity is max\n",
    "\n",
    "      Arguments:\n",
    "          patience: Number of epochs to wait after min has been hit. After this\n",
    "          number of no improvement, training stops.\n",
    "          eval_df, eval_features, tokenizer: Ground truth and tokenizer needed in\n",
    "          order to compute js\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eval_df, eval_features, tokenizer, patience=0):\n",
    "        super(EarlyStoppingAtMaxJaccardSimilarity, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.eval_df = eval_df\n",
    "        self.eval_features = eval_features\n",
    "        self.tokenizer = tokenizer\n",
    "        self.x_eval = [\n",
    "            np.array(eval_features[\"input_ids\"]),\n",
    "            np.array(eval_features[\"attention_mask\"]),\n",
    "            np.array(eval_features[\"token_type_ids\"]),\n",
    "        ]\n",
    "        # best_weights to store the weights at which the max JS occurs.\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # The number of epoch it has waited when loss is no longer minimum.\n",
    "        self.wait = 0\n",
    "        # The epoch the training stops at.\n",
    "        self.stopped_epoch = 0\n",
    "        # Initialize the best as infinity.\n",
    "        self.best = 0.0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        raw_predictions = self.model.predict(self.x_eval)\n",
    "        final_predictions = postprocess_predictions(\n",
    "            self.eval_df, self.eval_features, raw_predictions, self.tokenizer, verbose=False\n",
    "        )\n",
    "        Y_pred = [final_predictions[id_] for id_ in self.eval_df[\"id\"].values]\n",
    "        Y_true = self.eval_df[\"answer_text\"].values\n",
    "        jaccard_sim = [jaccard_similarity(Y_true[i], Y_pred[i]) for i in range(Y_true.shape[0])]\n",
    "        current = np.round(np.mean(jaccard_sim), 4)\n",
    "        print(f\"Validation jaccard similarity: {current}\")\n",
    "        \n",
    "        if current > self.best:\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            # Record the best weights if current results is better.\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                print(\"Restoring model weights from the end of the best epoch.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"Epoch %05d: early stopping\" % (self.stopped_epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-16T18:32:53.166629Z",
     "iopub.status.busy": "2021-10-16T18:32:53.166336Z",
     "iopub.status.idle": "2021-10-16T18:52:08.739242Z",
     "shell.execute_reply": "2021-10-16T18:52:08.736991Z",
     "shell.execute_reply.started": "2021-10-16T18:32:53.166596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:430: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 202019840 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483/483 [==============================] - 304s 326ms/step - loss: 6.7813 - flatten_loss: 3.3060 - flatten_1_loss: 3.4754 - val_loss: 2.3020 - val_flatten_loss: 1.0839 - val_flatten_1_loss: 1.2181\n",
      "Validation jaccard similarity: 0.6602\n",
      "Epoch 2/10\n",
      "483/483 [==============================] - 141s 292ms/step - loss: 2.4147 - flatten_loss: 1.1340 - flatten_1_loss: 1.2807 - val_loss: 1.7650 - val_flatten_loss: 0.8271 - val_flatten_1_loss: 0.9379\n",
      "Validation jaccard similarity: 0.6648\n",
      "Epoch 3/10\n",
      "483/483 [==============================] - 140s 290ms/step - loss: 1.8789 - flatten_loss: 0.8753 - flatten_1_loss: 1.0036 - val_loss: 1.5158 - val_flatten_loss: 0.7225 - val_flatten_1_loss: 0.7933\n",
      "Validation jaccard similarity: 0.6494\n",
      "Epoch 4/10\n",
      "483/483 [==============================] - 140s 291ms/step - loss: 1.6011 - flatten_loss: 0.7642 - flatten_1_loss: 0.8369 - val_loss: 1.3913 - val_flatten_loss: 0.6818 - val_flatten_1_loss: 0.7095\n",
      "Validation jaccard similarity: 0.6472\n",
      "Epoch 5/10\n",
      "483/483 [==============================] - 140s 290ms/step - loss: 1.4916 - flatten_loss: 0.7290 - flatten_1_loss: 0.7625 - val_loss: 1.3645 - val_flatten_loss: 0.6779 - val_flatten_1_loss: 0.6865\n",
      "Validation jaccard similarity: 0.6431\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-16 18:49:35.811777: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model written to muril-large-cased-f4\n"
     ]
    }
   ],
   "source": [
    "train_df = df.loc[df[\"kfold\"] != FOLD, :]\n",
    "val_df = df.loc[df[\"kfold\"] == FOLD, :]\n",
    "tokenized_train = prepare_train_features(train_df, tokenizer, MODEL_CONFIG)\n",
    "tokenized_val = prepare_train_features(val_df, tokenizer, MODEL_CONFIG)\n",
    "X_train, Y_train = create_model_input(tokenized_train)\n",
    "X_val, Y_val = create_model_input(tokenized_train)\n",
    "    \n",
    "eval_features = prepare_validation_features(val_df, tokenizer, MODEL_CONFIG)\n",
    "\n",
    "#early_stopping = tf.keras.callbacks.EarlyStopping(patience=1, restore_best_weights=True)\n",
    "#jaccard_similarity_callback = JaccardSimilarity(val_df, eval_features, tokenizer)\n",
    "#exact_match_callback = ExactMatch(val_df, eval_features, tokenizer)\n",
    "\n",
    "early_stopping_at_max_js = EarlyStoppingAtMaxJaccardSimilarity(\n",
    "    patience=3, eval_df=val_df, eval_features=eval_features, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=10,\n",
    "    batch_size=MODEL_CONFIG[\"batch_size\"],#64\n",
    "    validation_data=(X_val, Y_val),\n",
    "    callbacks=[early_stopping_at_max_js]\n",
    ")\n",
    "\n",
    "save_locally = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\n",
    "\n",
    "path = f\"{MODEL_CONFIG.model_name}-f{FOLD}\"\n",
    "model.save(path, options=save_locally)\n",
    "print(f\"Model written to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
